## 1. Host Setup:
The Xilinx Runtime (XRT) host application is supported on **Ubuntu 16.04 /18.04** and **CentOS 7.x.**
With **sudo access**, use the following command to download and run the setup script:

---

### 1.1 Install Docker (If not already installed)
+ [Install Docker](https://hub.docker.com/r/xilinx/vitis-ai-cpu/tags?page=1&ordering=last_updated) - if Docker not installed on your machine yet
+ [Ensure your linux user is in the group docker](https://docs.docker.com/install/linux/linux-postinstall/)

---

### 1.2 Clone GitHub Repository for Vitis AI
```bash
git clone --recurse-submodules https://github.com/Xilinx/Vitis-AI
cd Vitis-AI
```

---

### 1.3 Pull Docker Container
Download the latest Vitis AI Docker with the following command. This container runs on CPU.

```bash
docker pull xilinx/vitis-ai-cpu:latest
```

To run the docker, use command:

```bash
./docker_run.sh xilinx/vitis-ai-cpu:latest
```

---

## 2. Alveo U50 / U50LV / U280 / VCK5000 Setup
Follow the instructions here to set up the host and Alveo board:

For U50, U50LV and U280 card: [https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo](https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo)

For VCK5000 card: [https://github.com/Xilinx/Vitis-AI/tree/master/setup/vck5000](https://github.com/Xilinx/Vitis-AI/tree/master/setup/vck5000)

---

## 3 Running Vitis AI Library Examples for U50/U50lv/U280
### 3.1 Download Images and Videos
Download the [vitis_ai_library_r1.2.0_images.tar.gz](https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_library_r1.2.0_images.tar.gz) and [vitis_ai_library_r1.2.0_video.tar.gz packages](https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_library_r1.2.0_video.tar.gz) and untar them

```bash
cd /workspace
wget https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_library_r1.2.0_images.tar.gz -O vitis_ai_library_r1.2.0_images.tar.gz
wget https://www.xilinx.com/bin/public/openDownload?filename=vitis_ai_library_r1.2.0_video.tar.gz -O vitis_ai_library_r1.2.0_video.tar.gz
tar -xzvf vitis_ai_library_r1.2.0_images.tar.gz -C Vitis-AI-Library/overview
tar -xzvf vitis_ai_library_r1.2.0_video.tar.gz -C Vitis-AI-Library/overview
```

---

### 3.2 Download Models
**Download models for U50 / U50LV / U280** 

```bash
wget   https://www.xilinx.com/bin/public/openDownload?filename=densebox_320_320-u50-u50lv-u280-DPUCAHX8H-r1.4.0.tar.gz
sudo mkdir /usr/share/vitis_ai_library/models
tar -xvf  densebox_320_320-u50-u50lv-u280-DPUCAHX8H-r1.4.0.tar.gz -C /usr/share/vitis_ai_library/models
```

**Download models for VCK5000** 

```bash
wget:  https://www.xilinx.com/bin/public/openDownload?filename=densebox_320_320-u50-u50lv-u280-DPUCAHX8H-r1.4.0.tar.gz
sudo mkdir /usr/share/vitis_ai_library/models
tar -xvf  densebox_320_320-u50-u50lv-u280-DPUCAHX8H-r1.4.0.tar.gz -C /usr/share/vitis_ai_library/models
```

---

### 3.3 Enter the directory
Enter the directory of sample and then compile it. Take *facedetect* as an example.

```bash
cd /workspace/Vitis_AI_Library/overview/samples/facedetect
bash -x build.sh
```

---

### 3.4 Run the image test example

```bash
./test_jpeg_facedetect densebox_320_320 sample_facedetect.jpg
```

---

### 3.5 Run the program in batch
If you want to run the program in batch mode, which means that the DPU processes multiple images at once to prompt for processing performance, you have to compile the entire Vitis AI Library according to \"Setting Up the Host For Cloud\" section. Then the batch program will be generated under **build_dir_default**.
Enter **build_dir_default**, take *facedetect* as an example, execute the following command.

```bash
./test_facedetect_batch densebox_320_320 {img1_url} [{img2_url} ...]
```

---

### 3.6 Run the video test example

```bash
./test_video_facedetect densebox_320_320 video_input.mp4 -t 8
```
+ Video_input.mp4: The video file's name for input. The user needs to prepare the video file by themselves. 
+ -t: num_of_threads

---

### 3.7 Test the performance of model

```bash
./test_performance_facedetect densebox_320_320 test_performance_facedetect.list -t 8 -s 60
```
+ -t: num_of_threads
+ -s: num_of_seconds

---

## 4. Alveo U200 / U250 Setup

--- 

### 4.1 Change directories to the Alveo Tensorflow dir
```bash
cd alveo/examples/tensorflow
```

---

### 4.2 Activate Conda Environment
```bash
conda activate vitis-ai-tensorflow
```

DPU IP Selection
```bash
# Typically, {path-to-vitis-ai} is `/workspace`
source {path-to-vitis-ai}/setup/alveo/setup.sh DPUCADF8H
```

---

### 4.3 Setup the Environment
Please refer to the link to setup U200/U250 platform and xclbin:
[https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo](https://github.com/Xilinx/Vitis-AI/tree/master/setup/alveo)

---

### 4.4 Download a minimal validation set
Download a minimal validation set for [Imagenet2012](http://www.image-net.org/challenges/LSVRC/2012) using [Collective Knowledge (CK)](https://github.com/ctuning).
Note: User is responsible for the use of the downloaded content and compliance with any copyright licenses.

```bash
python -m ck pull repo:ck-env
python -m ck install package:imagenet-2012-val-min
python -m ck install package:imagenet-2012-aux
head -n 500 ~/CK-TOOLS/dataset-imagenet-ilsvrc2012-aux/val.txt > ~/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/val.txt
```

---

### 4.5 Download Samples Models
After the setup, run through a sample end-to-end Tensorflow classification example using the following steps that demonstrates preparing and deploying a trained Tensorflow model for FPGA acceleration using Xilinx Vitis-AI.

The following example uses the pretrained Resnet-50 Tensorflow model from the AI-Model-Zoo.

Download sample models from [AI-Model-Zoo](https://github.com/Xilinx/Vitis-AI/tree/master/models/AI-Model-Zoo)

---

### 4.6 End-to-End Classification for TF Resnet50
**Quantize the Model**

```bash
vai_q_tensorflow quantize \
--input_frozen_graph ./models/resnet_v1_50_inference.pb \
--input_nodes input \
--output_nodes resnet_v1_50/predictions/Reshape_1 \
--input_fn utils.input_fn_resnet50_v1_tf \
--input_shapes ?,224,224,3 \
--calib_iter 10
```

**Compile the model**

In this step, the network graph (xmodel file) is compiled using the Vitis-AI compiler. Note this may take approximately 5 minutes.

```bash
vai_c_tensorflow \
vai_c_tensorflow \
  --arch /opt/vitis_ai/compiler/arch/DPUCADF8H/U250/arch.json \
  --frozen_pb quantize_results/quantize_eval_model.pb \
  --output_dir out \
  --net_name resnet50_v1_tf_compiled \
  --options '{ \"input_shape\": \"4,224,224,3\"}'
```


**Run Inference**

This example code is derived from [VART demos](https://github.com/Xilinx/Vitis-AI/blob/master/demo/VART).


**Compile the executable**

```bash
./build.sh
```

**Prepare test images**

This demo will run on all images in the specified directory. e.g. ./images/


**Run**

```bash
./resnet_example ./resnet50_v1_tf_compiled.xmodel ./images/
```

---

## 5. Results and Next Steps
Once you have run through the examples, top 5 prediction scores will be displayed with the inference confidence.

Now that you have successfully tried one example, please refer to many other examples and applications available in the Vitis AI Github page: [https://github.com/Xilinx/Vitis-AI](https://github.com/Xilinx/Vitis-AI)

+ [Vitis-AI on Amazon AWS](https://github.com/Xilinx/Vitis-AI/tree/master/docs/aws)
+ [Vitis-AI on Microsoft Azure](https://github.com/Xilinx/Vitis-AI/tree/master/docs/azure)
